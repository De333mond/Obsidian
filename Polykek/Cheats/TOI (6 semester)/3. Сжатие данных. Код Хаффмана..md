#Polykek/cheats/TOI #понятие-информации

## Основные понятия 
Мы рассмотрим один из самых распространенных методов сжатия данных. Речь пойдет о коде Хаффмана (Huffman code) или минимальноизбыточном префиксном коде (minimum-redundancy prefix code). 

Мы начнем с главных определений, а затем перейдем к основным идеям кода Хаффмана и исследуем ряд важных свойств.

<u>Алгоритм Хаффмана</u> — жадный алгоритм оптимального префиксного кодирования алфавита с минимальной избыточностью. Был разработан в 1952 году аспирантом Массачусетского технологического института Дэвидом Хаффманом при написании им курсовой работы. Это широко используемый метод сжатия, присваивающий символам алфавита коды переменной длины, основываясь на вероятностях появления этих символов. В настоящее время используется во многих программах сжатия данных.

<u>Префиксный код</u> – это код, в котором никакое кодовое слово не является префиксом любого другого кодового слова. Эти коды имеют переменную длину.

<u>Оптимальный префиксный код</u> - это префиксный код, имеющий минимальную среднюю длину.

## Алгоритм Хаффмана

Идея, лежащая в основе кода Хаффмана, достаточно проста. Вместо того чтобы кодировать все символы одинаковым числом бит (как это сделано, например, в ASCII кодировке, где на каждый символ отводится ровно по 8 бит), будем кодировать символы, которые встречаются чаще, меньшим числом бит, чем те, которые встречаются реже. Более того, потребуем, чтобы код был оптимален или, другими словами, минимально-избыточен.

Стоит отметить, что за 50 лет со дня опубликования, код Хаффмана ничуть не потерял своей актуальности и значимости. Так с уверенностью можно сказать, что мы сталкиваемся с ним, в той или иной форме (дело в том, что код Хаффмана редко используется отдельно, чаще работая в связке с другими алгоритмами), практически каждый раз, когда архивируем файлы, смотрим фотографии, фильмы, посылаем факс или слушаем музыку.

Алгоритм Хаффмана можно разделить на два этапа: 
- **Определение вероятности появления символов в исходном тексте.** 
  
  Первоначально необходимо прочитать исходный текст полностью и подсчитать вероятности появления символов в нем (иногда подсчитывают, сколько раз встречается каждый символ). Если при этом учитываются все 256 символов, то не будет разницы в сжатии текстового или файла иного формата.
  
 
- **Нахождение оптимального префиксного кода.** 
  
  Далее находятся два символа a и b с наименьшими вероятностями появления и заменяются одним фиктивным символом x, который имеет вероятность появления, равную сумме вероятностей появления символов a и b. Затем, используя эту процедуру рекурсивно, находится оптимальный префиксный код для меньшего множества символов (где символы a и b заменены одним символом x). Код для исходного множества символов получается из кодов замещающих символов путем добавления 0 или 1 перед кодом замещающего символа, и эти два новых кода принимаются как коды заменяемых символов. Например, код символа a будет соответствовать коду x с добавленным нулем перед этим кодом, а для символа b перед кодом символа x будет добавлена единица.

## Дерево Хаффмана

Коды Хаффмана имеют уникальный префикс, что и позволяет однозначно их декодировать, несмотря на их переменную длину. Известно, что любому бинарному префиксному коду соответствует определенное бинарное дерево.

Первым этапом в реализации алгоритма будет – построение бинарного дерева или дерева Хаффмана.

Этапы построения:
1. Символы входного алфавита образуют список свободных узлов. Каждый узел имеет вес, равный вероятности появления символа в сжимаемом тексте.
2. Выбираются два свободных узла дерева с наименьшими весами. 
3. Создается их родитель с весом, равным их суммарному весу. После этого шага родитель рассматривается как свободный узел. 
4. Родитель добавляется в список свободных узлов, а двое его детей удаляются из этого списка. 
5. Одной дуге, выходящей из родителя, ставится в соответствие бит 1, другой – бит 0 (для определённости можно считать, что к узлу с бóльшим весом соответствует 1, с меньшим – 0). 
6. Повторяем шаги 2-6, пока в списке свободных узлов не останется только один свободный узел. Он и будет считаться корнем дерева.

### Пример построения дерева по методу Хаффмана:

Сжимаемое сообщение – AAABCCCCDEEEFG (то же, что при использовании алгоритма Шеннона-Фано). Соответственно: p(A) = 3/14, p(B) = 1/14, p(C) = 4/14, p(D) = 1/14, p(E) = 3/14, p(F) = 1/14, p(G) = 1/14. Пример дерева на рис. 1.

![[Pasted image 20240611064745.png]]

Двигаясь по нашему дереву, получим следующую таблицу(рис. 2) для кодировки:

![[Pasted image 20240611064804.png]]

Исходная последовательность AAABCCCCDEEEFG кодируется следующей: 01.01.01.1001.11.11.11.11.1000.00.00.00.1011.1010 – 36 бит (это лучше, чем в коде Шеннона-Фано). Нельзя забывать, что ни один код не должен являться префиксом другого!

### Недостатки алгоритма
Классический алгоритм Хаффмана имеет один существенный недостаток. Для восстановления содержимого сообщения декодер должен знать таблицу частот, которой пользовался кодер. Следовательно, длина сжатого сообщения увеличивается на длину таблицы частот, которая должна посылаться впереди данных, что приводит к увеличению размеров выходного файла. Кроме того, необходимость наличия полной частотной статистики перед началом собственно кодирования требует двух проходов по сообщению: одного для построения модели сообщения (таблицы частот и дерева), другого для собственно кодирования. 

Во-вторых, избыточность кодирования обращается в ноль лишь в тех случаях, когда вероятности кодируемых символов являются обратными степенями числа 2. 

В-третьих, для источника с энтропией, не превышающей 1 (например, для двоичного источника), непосредственное применение кода Хаффмана бессмысленно. 

Проблема обычного алгоритма сжатия по Хаффману — недетерминированность. Для похожих последовательностей могут получиться разные деревья, так и одно дерево без правильной сериализации может соответствовать разным последовательностям. Для избежания применяют канонические коды Хаффмана.

### Канонические коды Хаффмана

В этом алгоритме не строится дерево Хаффмана. 
Состоит из двух этапов: 
- Подсчёт длины кода для какого-то символа 
- Составление кода. 
  
Подводя итоги, можно сказать, что Алгоритм Хаффмана универсальный, его можно применять для сжатия данных любых типов, но он малоэффективен для файлов маленьких размеров (за счет необходимости сохранения словаря). В настоящее время данный метод практически не применяется в чистом виде, обычно используется как один из этапов сжатия в более сложных схемах. Это единственный алгоритм, который не увеличивает размер исходных данных в худшем случае (если не считать необходимости хранить таблицу перекодировки вместе с файлом).